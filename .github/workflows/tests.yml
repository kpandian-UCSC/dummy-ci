name: Code-Quality

on:
  push:
    branches: [main]
  pull_request:
    branches: [main, feature/**]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v2
    - name: Set up Python 
      uses: actions/setup-python@v2
      with:
        python-version: 3.7
    - name: Install dependencies
      run: |
        python3 -m pip install --upgrade pip
        pip3 install pylint
        pip3 install boto3
    - name: Analysing the code with pylint
      run: |
        pylint $(git ls-files '*.py')
  
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Check out repository code
        uses: actions/checkout@v2
      - name: Setup Python
        uses: actions/setup-python@v2
        with:
          python-version: 3.7

      - name: Install pip
        run: |
          python -m pip install --upgrade pipenv wheel
      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pip3 install -r requirements.txt
      - name: Run test suite
        run: |
          pytest ./tests/*.py

  auto-deploy-to-lambda:
    runs-on: ubuntu-latest
    needs: [lint, test]
    # if: github.ref == 'refs/heads/main'
    steps:      
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      #does this mean that the files in my github repo are accessible by this YAML file?
      - uses: actions/checkout@v2
      
      #installs a version of python, but I need this if deploying to a severless Python Lambda?
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: '3.7'
      
      - name: Configure AWS credentials from Production account
        uses: aws-actions/configure-aws-credentials@v1
        with:
          # TODO:::
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-west-1
      
      - name: Install pip
        run: |
          python -m pip install --upgrade pipenv wheel
      - name: Install dependencies
        if: steps.cache-pipenv.outputs.cache-hit != 'true'
        run: |
          pip3 install -r requirements.txt
          pip3 install boto3
      - name: Deploy
        run: |
          zip -j deploy.zip ./src/* #--> Zip the Code As we know lambda function accept the zip file.
          bash scripts/release.sh ${{secrets.AWS_S3_BUCKET}} "deploy.zip" ${{secrets.AWS_ACCESS_KEY_ID}} ${{secrets.AWS_SECRET_ACCESS_KEY}} "deploy.zip"
          # aws lambda update-function-code --function-name=lambda-gh-action-test --zip-file=fileb://deploy.zip 
          aws cloudformation create-stack --stack-name Databricks-IR-Framework --template-body Development --parameters S3BucketName=${{secrets.AWS_S3_BUCKET}},S3BucketKey=deploy.zip